{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from H_10_models import SmallNetwork, MediumNetwork, LargeNetwork, ResLinearNetwork, LSTMNetwork\n",
    "from model_configs import ModelDimConfigs, TrainingConfigs\n",
    "from misc_tools import get_timestamp, ARPABET\n",
    "from model_dataset import DS_Tools, Padder, TokenMap, NormalizerKeepShape\n",
    "from model_dataset import SingleRecSelectBalanceDatasetPrecombine as ThisDataset\n",
    "from model_filter import XpassFilter\n",
    "from paths import *\n",
    "from ssd_paths import *\n",
    "from misc_progress_bar import draw_progress_bar\n",
    "from misc_recorder import *\n",
    "from H_11_drawer import draw_learning_curve_and_accuracy\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(type=\"f\", sel=\"full\", load=\"train\"):\n",
    "    if type == \"l\":\n",
    "        mytrans = nn.Sequential(\n",
    "            Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "            XpassFilter(cut_off_upper=500),\n",
    "            torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                                n_mels=TrainingConfigs.N_MELS, \n",
    "                                                n_fft=TrainingConfigs.N_FFT, \n",
    "                                                power=2), \n",
    "            torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "            NormalizerKeepShape(NormalizerKeepShape.norm_mvn)\n",
    "        )\n",
    "    elif type == \"h\": \n",
    "        mytrans = nn.Sequential(\n",
    "            Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "            XpassFilter(cut_off_upper=10000, cut_off_lower=4000),\n",
    "            torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                                n_mels=TrainingConfigs.N_MELS, \n",
    "                                                n_fft=TrainingConfigs.N_FFT, \n",
    "                                                power=2), \n",
    "            torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "            NormalizerKeepShape(NormalizerKeepShape.norm_mvn)\n",
    "        )\n",
    "    else: \n",
    "        mytrans = nn.Sequential(\n",
    "            Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "            torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                                n_mels=TrainingConfigs.N_MELS, \n",
    "                                                n_fft=TrainingConfigs.N_FFT, \n",
    "                                                power=2), \n",
    "            torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "            NormalizerKeepShape(NormalizerKeepShape.norm_mvn)\n",
    "        )\n",
    "    with open(os.path.join(src_, \"no-stress-seg.dict\"), \"rb\") as file:\n",
    "        # Load the object from the file\n",
    "        mylist = pickle.load(file)\n",
    "        mylist.remove('AH') # we don't include this, it is too mixed. \n",
    "\n",
    "    if sel == \"c\": \n",
    "        select = ARPABET.intersect_lists(mylist, ARPABET.list_consonants())\n",
    "    elif sel == \"v\":\n",
    "        select = ARPABET.intersect_lists(mylist, ARPABET.list_vowels())\n",
    "    else:\n",
    "        select = mylist\n",
    "    # Now you can use the loaded object\n",
    "    mymap = TokenMap(mylist)\n",
    "    if load == \"train\": \n",
    "        train_ds = ThisDataset(strain_cut_audio_, \n",
    "                            os.path.join(suse_, \"guide_train.csv\"), \n",
    "                            select=select, \n",
    "                            mapper=mymap, \n",
    "                            transform=mytrans)\n",
    "        \n",
    "        # train_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, f\"train_{sel}.use\"))\n",
    "        # use_train_ds = torch.utils.data.Subset(train_ds, train_ds_indices)\n",
    "        use_train_ds = train_ds\n",
    "        train_loader = DataLoader(use_train_ds, batch_size=TrainingConfigs.BATCH_SIZE, \n",
    "                                shuffle=True, \n",
    "                                num_workers=TrainingConfigs.LOADER_WORKER)\n",
    "        \n",
    "        return train_loader\n",
    "    elif load == \"valid\":\n",
    "        valid_ds = ThisDataset(strain_cut_audio_, \n",
    "                            os.path.join(suse_, \"guide_validation.csv\"), \n",
    "                            select=select, \n",
    "                            mapper=mymap,\n",
    "                            transform=mytrans)\n",
    "        # valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, f\"valid_{sel}.use\"))\n",
    "        # use_valid_ds = torch.utils.data.Subset(valid_ds, valid_ds_indices)\n",
    "        use_valid_ds = valid_ds\n",
    "        valid_loader = DataLoader(use_valid_ds, batch_size=TrainingConfigs.BATCH_SIZE, \n",
    "                                shuffle=False, \n",
    "                                num_workers=TrainingConfigs.LOADER_WORKER)\n",
    "        return valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lffl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
