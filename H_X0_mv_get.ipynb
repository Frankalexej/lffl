{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from H_10_models import SmallNetwork, MediumNetwork, LargeNetwork, ResLinearNetwork, LSTMNetwork\n",
    "from model_configs import ModelDimConfigs, TrainingConfigs\n",
    "from misc_tools import get_timestamp, ARPABET\n",
    "from model_dataset import DS_Tools, Padder, TokenMap, NormalizerKeepShape\n",
    "from model_dataset import SingleRecSelectBalanceDatasetPrecombine as ThisDataset\n",
    "from model_filter import XpassFilter\n",
    "from paths import *\n",
    "from ssd_paths import *\n",
    "from misc_progress_bar import draw_progress_bar\n",
    "from misc_recorder import *\n",
    "from H_11_drawer import draw_learning_curve_and_accuracy\n",
    "import argparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfigs: \n",
    "    # BATCH_SIZE = 64\n",
    "    BATCH_SIZE = 256 # NOTE: 20240813 changed to 32 due to smaller data size. \n",
    "\n",
    "    REC_SAMPLE_RATE = 16000\n",
    "    N_FFT = 400\n",
    "    N_MELS = 64\n",
    "\n",
    "    N_MFCC = 13\n",
    "\n",
    "    N_SPEC = 201\n",
    "    \n",
    "    LOADER_WORKER = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(type=\"f\", sel=\"full\", load=\"train\", model_save_dir=\"\"):\n",
    "    if type == \"l\":\n",
    "        mytrans = nn.Sequential(\n",
    "            Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "            XpassFilter(cut_off_upper=500),\n",
    "            torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                                n_mels=TrainingConfigs.N_MELS, \n",
    "                                                n_fft=TrainingConfigs.N_FFT, \n",
    "                                                power=2), \n",
    "            torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "            # NormalizerKeepShape(NormalizerKeepShape.norm_mvn)\n",
    "        )\n",
    "    elif type == \"h\": \n",
    "        mytrans = nn.Sequential(\n",
    "            Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "            XpassFilter(cut_off_upper=10000, cut_off_lower=4000),\n",
    "            torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                                n_mels=TrainingConfigs.N_MELS, \n",
    "                                                n_fft=TrainingConfigs.N_FFT, \n",
    "                                                power=2), \n",
    "            torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "            # NormalizerKeepShape(NormalizerKeepShape.norm_mvn)\n",
    "        )\n",
    "    else: \n",
    "        mytrans = nn.Sequential(\n",
    "            Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "            torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                                n_mels=TrainingConfigs.N_MELS, \n",
    "                                                n_fft=TrainingConfigs.N_FFT, \n",
    "                                                power=2), \n",
    "            torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "            # NormalizerKeepShape(NormalizerKeepShape.norm_mvn)\n",
    "            # We don't want to use normalizer here \n",
    "        )\n",
    "    with open(os.path.join(src_, \"no-stress-seg.dict\"), \"rb\") as file:\n",
    "        # Load the object from the file\n",
    "        mylist = pickle.load(file)\n",
    "        mylist.remove('AH') # we don't include this, it is too mixed. \n",
    "\n",
    "    if sel == \"c\": \n",
    "        select = ARPABET.intersect_lists(mylist, ARPABET.list_consonants())\n",
    "    elif sel == \"v\":\n",
    "        select = ARPABET.intersect_lists(mylist, ARPABET.list_vowels())\n",
    "    else:\n",
    "        select = mylist\n",
    "    # Now you can use the loaded object\n",
    "    mymap = TokenMap(mylist)\n",
    "    if load == \"train\": \n",
    "        train_ds = ThisDataset(strain_cut_audio_, \n",
    "                            os.path.join(suse_, \"guide_train.csv\"), \n",
    "                            select=select, \n",
    "                            mapper=mymap, \n",
    "                            transform=mytrans)\n",
    "        \n",
    "        train_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, f\"train_{sel}.use\"))\n",
    "        use_train_ds = torch.utils.data.Subset(train_ds, train_ds_indices)\n",
    "        # use_train_ds = train_ds\n",
    "        train_loader = DataLoader(use_train_ds, batch_size=TrainingConfigs.BATCH_SIZE, \n",
    "                                shuffle=True, \n",
    "                                num_workers=TrainingConfigs.LOADER_WORKER)\n",
    "        \n",
    "        return train_loader\n",
    "    elif load == \"valid\":\n",
    "        valid_ds = ThisDataset(strain_cut_audio_, \n",
    "                            os.path.join(suse_, \"guide_validation.csv\"), \n",
    "                            select=select, \n",
    "                            mapper=mymap,\n",
    "                            transform=mytrans)\n",
    "        valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, f\"valid_{sel}.use\"))\n",
    "        use_valid_ds = torch.utils.data.Subset(valid_ds, valid_ds_indices)\n",
    "        # use_valid_ds = valid_ds\n",
    "        valid_loader = DataLoader(use_valid_ds, batch_size=TrainingConfigs.BATCH_SIZE, \n",
    "                                shuffle=False, \n",
    "                                num_workers=TrainingConfigs.LOADER_WORKER)\n",
    "        return valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store per-iteration statistics\n",
    "means = []\n",
    "variances = []\n",
    "sample_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:02<00:00, 36.30it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 47.79it/s] \n",
      "100%|██████████| 98/98 [00:02<00:00, 48.74it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 52.85it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 48.79it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 40.75it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 48.21it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 47.32it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 43.70it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 47.83it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 49.32it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 49.05it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 46.59it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 45.74it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 45.05it/s]\n",
      "100%|██████████| 98/98 [00:02<00:00, 48.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for run in range(5, 21): \n",
    "    # Read in the dataset\n",
    "    ts = \"0905160507\"\n",
    "    train_name = \"H21\"\n",
    "    model_save_dir = os.path.join(model_save_, f\"{train_name}-{ts}-{run}\")\n",
    "\n",
    "    train_loader = load_data(type=\"f\", \n",
    "                            load=\"train\", \n",
    "                            model_save_dir=model_save_dir)\n",
    "    # We use normal dataset, but just deleted the normalizer from my_trans\n",
    "    # In this way, we just loop over the batches and collect the mels. \n",
    "    all_mels = []\n",
    "    for x, y in tqdm(train_loader):\n",
    "        all_mels.append(x)\n",
    "\n",
    "    all_mels_cat = torch.cat(all_mels, dim=0)\n",
    "\n",
    "    # Compute mean and variance for this iteration\n",
    "    iteration_mean = all_mels_cat.mean()\n",
    "    iteration_var = all_mels_cat.var(unbiased=True)  # Unbiased variance\n",
    "    iteration_samples = all_mels_cat.numel()         # Total number of elements\n",
    "\n",
    "    means.append(iteration_mean)\n",
    "    variances.append(iteration_var)\n",
    "    sample_counts.append(iteration_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Mean: -41.01996612548828, Estimated Std: 20.34762954711914\n"
     ]
    }
   ],
   "source": [
    "# Aggregate results to compute total mean and variance\n",
    "total_samples = sum(sample_counts)\n",
    "\n",
    "# Compute total mean\n",
    "total_mean = sum(n * m for n, m in zip(sample_counts, means)) / total_samples\n",
    "\n",
    "# Compute total variance\n",
    "total_variance = sum(n * (v + m**2) for n, v, m in zip(sample_counts, variances, means)) / total_samples - total_mean**2\n",
    "\n",
    "# Compute total standard deviation\n",
    "total_std = torch.sqrt(total_variance)\n",
    "\n",
    "print(f\"Estimated Mean: {total_mean}, Estimated Std: {total_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated Mean: -41.035614013671875, Estimated Std: 20.338979721069336\n",
    "# Estimated Mean: -41.01996612548828, Estimated Std: 20.34762954711914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_dict = {'mean': total_mean, 'std': total_std}\n",
    "\n",
    "with open(os.path.join(src_, \"mv_config_20.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(mean_std_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lffl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
