{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import os\n",
    "from model_configs import ModelDimConfigs, TrainingConfigs\n",
    "from misc_tools import get_timestamp, ARPABET\n",
    "from model_dataset import DS_Tools, Padder, TokenMap, NormalizerKeepShape\n",
    "from model_dataset import SingleRecSelectBalanceDatasetPrecombine as ThisDataset\n",
    "from model_filter import XpassFilter\n",
    "from paths import *\n",
    "from ssd_paths import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrans = nn.Sequential(\n",
    "    Padder(sample_rate=TrainingConfigs.REC_SAMPLE_RATE, pad_len_ms=250, noise_level=1e-4), \n",
    "    torchaudio.transforms.MelSpectrogram(TrainingConfigs.REC_SAMPLE_RATE, \n",
    "                                        n_mels=TrainingConfigs.N_MELS, \n",
    "                                        n_fft=TrainingConfigs.N_FFT, \n",
    "                                        power=2), \n",
    "    torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80), \n",
    "    NormalizerKeepShape(NormalizerKeepShape.norm_mvn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(src_, \"no-stress-seg.dict\"), \"rb\") as file:\n",
    "    # Load the object from the file\n",
    "    mylist = pickle.load(file)\n",
    "    mylist.remove('AH') # we don't include this, it is too mixed. \n",
    "select = mylist\n",
    "mymap = TokenMap(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = os.path.join(model_save_, \"H12-00000000001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = ThisDataset(strain_cut_audio_, \n",
    "                    os.path.join(suse_, \"guide_validation.csv\"), \n",
    "                    select=select, \n",
    "                    mapper=mymap,\n",
    "                    transform=mytrans)\n",
    "valid_ds_indices = DS_Tools.read_indices(os.path.join(model_save_dir, f\"valid.use\"))\n",
    "use_valid_ds = torch.utils.data.Subset(valid_ds, valid_ds_indices)\n",
    "valid_loader = DataLoader(use_valid_ds, batch_size=TrainingConfigs.BATCH_SIZE, \n",
    "                        shuffle=False, \n",
    "                        num_workers=TrainingConfigs.LOADER_WORKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 21])\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(valid_loader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(valid_loader):\n",
    "    print(x.shape)\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(16), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "        )\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin_1 = nn.Sequential(\n",
    "            nn.Linear(16 * 32 * 10, 128),  # Reduced size\n",
    "            nn.Dropout(0.5),  # Adjusted dropout rate\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(128, 64),  # Reduced size\n",
    "        )\n",
    "        self.lin = nn.Linear(in_features=128, out_features=38)\n",
    "\n",
    "        self.conv.apply(self.init_conv_weights)\n",
    "        self.lin.apply(self.init_lin_weights)\n",
    "\n",
    "    def init_lin_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # torch.nn.init.xavier_normal_(m.weight)\n",
    "            torch.nn.init.kaiming_normal_(m.weight, a=0.1)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def init_conv_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.kaiming_normal_(m.weight, a=0.1)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.ap(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.lin_1(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    def predict_on_output(self, output): \n",
    "        output = nn.Softmax(dim=1)(output)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        return preds\n",
    "\n",
    "class MediumNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(16), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin_1 = nn.Sequential(\n",
    "            nn.Linear(64 * 16 * 5, 128),  # Reduced size\n",
    "            nn.Dropout(0.5),  # Adjusted dropout rate\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.lin = nn.Linear(in_features=128, out_features=38)\n",
    "\n",
    "        self.conv.apply(self.init_conv_weights)\n",
    "        self.lin.apply(self.init_lin_weights)\n",
    "\n",
    "    def init_lin_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # torch.nn.init.xavier_normal_(m.weight)\n",
    "            torch.nn.init.kaiming_normal_(m.weight, a=0.1)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def init_conv_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.kaiming_normal_(m.weight, a=0.1)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.ap(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.lin_1(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    def predict_on_output(self, output): \n",
    "        output = nn.Softmax(dim=1)(output)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        return preds\n",
    "    \n",
    "# Large Model\n",
    "class LargeNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(16), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(256), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin_1 = nn.Sequential(\n",
    "            nn.Linear(256 * 8 * 2, 128), \n",
    "            nn.Dropout(0.5), \n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(512, 256),\n",
    "        )\n",
    "        self.lin = nn.Linear(in_features=128, out_features=38)\n",
    "\n",
    "        self.conv.apply(self.init_conv_weights)\n",
    "        self.lin.apply(self.init_lin_weights)\n",
    "\n",
    "    def init_lin_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # torch.nn.init.xavier_normal_(m.weight)\n",
    "            torch.nn.init.kaiming_normal_(m.weight, a=0.1)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def init_conv_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            torch.nn.init.kaiming_normal_(m.weight, a=0.1)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.ap(x)\n",
    "        # x = x.view(x.shape[0], -1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.lin_1(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "    def predict_on_output(self, output): \n",
    "        output = nn.Softmax(dim=1)(output)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SmallNetwork                             [64, 38]                  --\n",
       "├─Sequential: 1-1                        [64, 16, 32, 10]          --\n",
       "│    └─Conv2d: 2-1                       [64, 16, 64, 21]          160\n",
       "│    └─BatchNorm2d: 2-2                  [64, 16, 64, 21]          32\n",
       "│    └─ReLU: 2-3                         [64, 16, 64, 21]          --\n",
       "│    └─MaxPool2d: 2-4                    [64, 16, 32, 10]          --\n",
       "├─Sequential: 1-2                        [64, 128]                 --\n",
       "│    └─Linear: 2-5                       [64, 128]                 655,488\n",
       "│    └─Dropout: 2-6                      [64, 128]                 --\n",
       "│    └─BatchNorm1d: 2-7                  [64, 128]                 256\n",
       "│    └─ReLU: 2-8                         [64, 128]                 --\n",
       "├─Linear: 1-3                            [64, 38]                  4,902\n",
       "==========================================================================================\n",
       "Total params: 660,838\n",
       "Trainable params: 660,838\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 56.05\n",
       "==========================================================================================\n",
       "Input size (MB): 0.34\n",
       "Forward/backward pass size (MB): 22.17\n",
       "Params size (MB): 2.64\n",
       "Estimated Total Size (MB): 25.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(SmallNetwork(), input_size=(64, 1, 64, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MediumNetwork                            [64, 38]                  --\n",
       "├─Sequential: 1-1                        [64, 64, 16, 5]           --\n",
       "│    └─Conv2d: 2-1                       [64, 16, 64, 21]          160\n",
       "│    └─BatchNorm2d: 2-2                  [64, 16, 64, 21]          32\n",
       "│    └─ReLU: 2-3                         [64, 16, 64, 21]          --\n",
       "│    └─MaxPool2d: 2-4                    [64, 16, 32, 10]          --\n",
       "│    └─Conv2d: 2-5                       [64, 64, 32, 10]          9,280\n",
       "│    └─BatchNorm2d: 2-6                  [64, 64, 32, 10]          128\n",
       "│    └─ReLU: 2-7                         [64, 64, 32, 10]          --\n",
       "│    └─MaxPool2d: 2-8                    [64, 64, 16, 5]           --\n",
       "├─Sequential: 1-2                        [64, 128]                 --\n",
       "│    └─Linear: 2-9                       [64, 128]                 655,488\n",
       "│    └─Dropout: 2-10                     [64, 128]                 --\n",
       "│    └─BatchNorm1d: 2-11                 [64, 128]                 256\n",
       "│    └─ReLU: 2-12                        [64, 128]                 --\n",
       "├─Linear: 1-3                            [64, 38]                  4,902\n",
       "==========================================================================================\n",
       "Total params: 670,246\n",
       "Trainable params: 670,246\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 246.11\n",
       "==========================================================================================\n",
       "Input size (MB): 0.34\n",
       "Forward/backward pass size (MB): 43.14\n",
       "Params size (MB): 2.68\n",
       "Estimated Total Size (MB): 46.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(MediumNetwork(), input_size=(64, 1, 64, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LargeNetwork                             [64, 38]                  --\n",
       "├─Sequential: 1-1                        [64, 256, 8, 2]           --\n",
       "│    └─Conv2d: 2-1                       [64, 16, 64, 21]          160\n",
       "│    └─BatchNorm2d: 2-2                  [64, 16, 64, 21]          32\n",
       "│    └─ReLU: 2-3                         [64, 16, 64, 21]          --\n",
       "│    └─MaxPool2d: 2-4                    [64, 16, 32, 10]          --\n",
       "│    └─Conv2d: 2-5                       [64, 64, 32, 10]          9,280\n",
       "│    └─BatchNorm2d: 2-6                  [64, 64, 32, 10]          128\n",
       "│    └─ReLU: 2-7                         [64, 64, 32, 10]          --\n",
       "│    └─MaxPool2d: 2-8                    [64, 64, 16, 5]           --\n",
       "│    └─Conv2d: 2-9                       [64, 256, 16, 5]          147,712\n",
       "│    └─BatchNorm2d: 2-10                 [64, 256, 16, 5]          512\n",
       "│    └─ReLU: 2-11                        [64, 256, 16, 5]          --\n",
       "│    └─MaxPool2d: 2-12                   [64, 256, 8, 2]           --\n",
       "├─Sequential: 1-2                        [64, 128]                 --\n",
       "│    └─Linear: 2-13                      [64, 128]                 524,416\n",
       "│    └─Dropout: 2-14                     [64, 128]                 --\n",
       "│    └─BatchNorm1d: 2-15                 [64, 128]                 256\n",
       "│    └─ReLU: 2-16                        [64, 128]                 --\n",
       "├─Linear: 1-3                            [64, 38]                  4,902\n",
       "==========================================================================================\n",
       "Total params: 687,398\n",
       "Trainable params: 687,398\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 994.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.34\n",
       "Forward/backward pass size (MB): 64.11\n",
       "Params size (MB): 2.75\n",
       "Estimated Total Size (MB): 67.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(LargeNetwork(), input_size=(64, 1, 64, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = os.path.join(model_save_, \"H20-0325204212-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = DS_Tools.read_indices(os.path.join(model_save_dir, f\"train_full.use\"))\n",
    "vfs = DS_Tools.read_indices(os.path.join(model_save_dir, f\"valid_full.use\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28139"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfs) + len(vfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lffl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
